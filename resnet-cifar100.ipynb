{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.layers import ReLU, Add, Flatten\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to deal with tensorflow GPU errors\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'lr':0.001,\n",
    "    'epochs':100,\n",
    "    'img_size':32,\n",
    "    'n_classes':100,\n",
    "    'batch_size':64,\n",
    "    'n':2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(images):\n",
    "    images = images.astype(np.float32)\n",
    "    mean_vals = ()\n",
    "    std_vals = ()\n",
    "    for i in range(images.shape[-1]):\n",
    "        mean_vals += (np.mean(images[:, :, :, i]),)\n",
    "        std_vals += (np.std(images[:, :, :, i]),)\n",
    "    return mean_vals, std_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129.30428, 124.07023, 112.43411)\n",
      "(68.17024, 65.391785, 70.4184)\n"
     ]
    }
   ],
   "source": [
    "mean_vals, std_vals = get_mean_std(x_train)\n",
    "print(mean_vals)\n",
    "print(std_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images, mean_vals, std_vals):\n",
    "    images = images.astype(np.float32)\n",
    "    for i in range(images.shape[-1]):\n",
    "        images[:, :, :, i] = (images[:, :, :, i] - mean_vals[i])/std_vals[i]\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0245545 -1.8973366\n"
     ]
    }
   ],
   "source": [
    "x_train = normalize(x_train, mean_vals, std_vals)\n",
    "x_test = normalize(x_test, mean_vals, std_vals)\n",
    "print(x_test.max(), x_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    img_size = image.shape[0]\n",
    "    image = tf.image.resize_with_crop_or_pad(image, img_size + 4, img_size + 4)\n",
    "    image = tf.image.random_crop(image, size=(img_size, img_size, 3))\n",
    "    image = tf.image.random_contrast(image, 0.2, 0.5)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing into train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = 0.2\n",
    "perm_ids = np.random.permutation(x_train.shape[0])\n",
    "val_ids = perm_ids[:int(val_frac*x_train.shape[0])]\n",
    "train_ids = perm_ids[int(val_frac*x_train.shape[0]):]\n",
    "x_val, y_val = x_train[val_ids], y_train[val_ids]\n",
    "x_train, y_train = x_train[train_ids], y_train[train_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                           .map(augment, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "                           .shuffle(x_train.shape[0])\n",
    "                           .batch(args['batch_size'])\n",
    "                           )\n",
    "val_ds = (tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "                         .batch(args['batch_size'])\n",
    "                         )\n",
    "test_ds = (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "                          .batch(args['batch_size'])\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing if data loaders work properly\n",
    "for images, targets in train_ds.take(1):\n",
    "    for i in range(1):\n",
    "        plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet model (copied from https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/blob/master/zoo/resnet/resnet_cifar10.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(inputs):\n",
    "    ''' Construct the Stem Convolutional Group \n",
    "        inputs : the input vector\n",
    "    '''\n",
    "    x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "    \n",
    "def learner(x, n_blocks):\n",
    "    \"\"\" Construct the Learner\n",
    "        x          : input to the learner\n",
    "        n_blocks   : number of blocks in a group\n",
    "    \"\"\"\n",
    "    # First Residual Block Group of 16 filters (Stage 1)\n",
    "    # Quadruple (4X) the size of filters to fit the next Residual Group\n",
    "    x = residual_group(x, 16, n_blocks, strides=(1, 1), n=4)\n",
    "\n",
    "    # Second Residual Block Group of 64 filters (Stage 2)\n",
    "    # Double (2X) the size of filters and reduce feature maps by 75% (strides=2) to fit the next Residual Group\n",
    "    x = residual_group(x, 64, n_blocks, n=2)\n",
    "\n",
    "    # Third Residual Block Group of 64 filters (Stage 3)\n",
    "    # Double (2X) the size of filters and reduce feature maps by 75% (strides=2) to fit the next Residual Group\n",
    "    x = residual_group(x, 128, n_blocks, n=2)\n",
    "    return x\n",
    "\n",
    "def residual_group(x, n_filters, n_blocks, strides=(2, 2), n=2):\n",
    "    \"\"\" Construct a Residual Group\n",
    "        x         : input into the group\n",
    "        n_filters : number of filters for the group\n",
    "        n_blocks  : number of residual blocks with identity link\n",
    "        strides   : whether the projection block is a strided convolution\n",
    "        n         : multiplier for the number of filters out\n",
    "    \"\"\"\n",
    "    # Double the size of filters to fit the first Residual Group\n",
    "    x = projection_block(x, n_filters, strides=strides, n=n)\n",
    "\n",
    "    # Identity residual blocks\n",
    "    for _ in range(n_blocks):\n",
    "        x = identity_block(x, n_filters, n)\n",
    "    return x\n",
    "    \n",
    "def identity_block(x, n_filters, n=2):\n",
    "    \"\"\" Construct a Bottleneck Residual Block of Convolutions with Identity Shortcut\n",
    "        x        : input into the block\n",
    "        n_filters: number of filters\n",
    "        n        : multiplier for filters out\n",
    "    \"\"\"\n",
    "    # Save input vector (feature maps) for the identity link\n",
    "    shortcut = x\n",
    "    \n",
    "    ## Construct the 1x1, 3x3, 1x1 residual block (fig 3c)\n",
    "\n",
    "    # Dimensionality reduction\n",
    "    x = Conv2D(n_filters, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Bottleneck layer\n",
    "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Dimensionality restoration - increase the number of output filters by 2X or 4X\n",
    "    x = Conv2D(n_filters * n, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add the identity link (input) to the output of the residual block\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def projection_block(x, n_filters, strides=(2,2), n=2):\n",
    "    \"\"\" Construct Bottleneck Residual Block with Projection Shortcut\n",
    "        Increase the number of filters by 2X (or 4X on first stage)\n",
    "        x        : input into the block\n",
    "        n_filters: number of filters\n",
    "        strides  : whether the first convolution is strided\n",
    "        n        : multiplier for number of filters out\n",
    "    \"\"\"\n",
    "    # Construct the projection shortcut\n",
    "    # Increase filters by 2X (or 4X) to match shape when added to output of block\n",
    "    shortcut = Conv2D(n_filters * n, (1, 1), strides=strides, kernel_initializer='he_normal')(x)\n",
    "\n",
    "    ## Construct the 1x1, 3x3, 1x1 convolution block\n",
    "\n",
    "    # Dimensionality reduction\n",
    "    x = Conv2D(n_filters, (1, 1), strides=(1,1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Bottleneck layer - feature pooling when strides=(2, 2)\n",
    "    x = Conv2D(n_filters, (3, 3), strides=strides, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)  \n",
    "    \n",
    "    # Dimensionality restoration - increase the number of filters by 2X (or 4X)\n",
    "    x = Conv2D(n_filters * n, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add the projection shortcut to the output of the residual block\n",
    "    x = Add()([shortcut, x])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "    \n",
    "def classifier(x, n_classes):\n",
    "    ''' Construct the Classifier\n",
    "        x         : input into the classifier\n",
    "        n_classes : number of classes\n",
    "    '''\n",
    "    # Pool the feature maps after the end of all the residual blocks\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    \n",
    "    # Flatten into 1D vector\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Final Dense Outputting Layer \n",
    "    outputs = Dense(n_classes, activation='softmax', kernel_initializer='he_normal')(x)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(args):\n",
    "    n = args['n']    \n",
    "    depth =  n * 9 + 2\n",
    "    n_blocks = ((depth - 2) // 9) - 1\n",
    "    num_classes = args['n_classes']\n",
    "    input_shape = (args['img_size'], args['img_size'], 3)\n",
    "    inputs = Input(input_shape)\n",
    "    x = stem(inputs) \n",
    "    x = learner(x, n_blocks)\n",
    "    outputs = classifier(x, num_classes)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(args)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 10), \n",
    "             ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 5, verbose = 1)]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=args['lr']), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.compile(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = args['epochs'],\n",
    "    callbacks = callbacks,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'], label = \"Training loss\")\n",
    "plt.plot(history.history['val_loss'], label = \"Validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['accuracy'], label = \"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6684\\2204412912.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['lr'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50f8cb3f9f35f1e4806338cbd00de9dd66d8c70f21ba5be292c70ff31941a258"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
